{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "745ccf5a-3d79-48cd-a097-74397e796511",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "OPTIMIZE\n",
    "--------------------------------------------------------------------------------\n",
    "What it does:\n",
    "\n",
    "When data is written to a Delta table, Databricks stores it in many small Parquet files (especially after streaming or incremental loads).\n",
    "Too many small files = slow query performance.\n",
    "\n",
    "The OPTIMIZE command compacts small files into bigger, well-organized ones.\n",
    "--------------------------------------------------------------------------------\n",
    "Why it‚Äôs important?\n",
    "\n",
    "Reduces the number of files ‚Üí faster reads\n",
    "\n",
    "Makes queries more efficient\n",
    "\n",
    "Helps Z-Ordering perform better later\n",
    "-------------------------------------------------------------------------------\n",
    "When to use?\n",
    "\n",
    "After large inserts or merges\n",
    "\n",
    "At the end of your daily ETL pipeline\n",
    "\n",
    "Before Z-Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11e4f39d-0407-44aa-8003-5d7ebf4d10a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"USE CATALOG safe_sure_catalog\")\n",
    "spark.sql(\"USE SCHEMA gold\")\n",
    "\n",
    "spark.sql(\"OPTIMIZE gold.transaction\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c1296a8-0c16-491a-9643-9b599e31ac5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "\n",
    "knowing *what happens* when you run `OPTIMIZE` helps you understand what‚Äôs going on ‚Äúunder the hood.‚Äù\n",
    "\n",
    "Let‚Äôs break it down üëá\n",
    "\n",
    "---\n",
    "\n",
    "### üß± What Happens When You Run:\n",
    "\n",
    "```sql\n",
    "OPTIMIZE gold.transaction;\n",
    "```\n",
    "\n",
    "1Ô∏è‚É£ **Delta Lake scans your table**\n",
    "\n",
    "* It looks inside the Delta log (`_delta_log` folder) to find all Parquet files that belong to `gold.transaction`.\n",
    "\n",
    "2Ô∏è‚É£ **It identifies many small files**\n",
    "\n",
    "* Especially after streaming or incremental writes, Delta creates hundreds of small files (like 1‚Äì5 MB each).\n",
    "* Too many small files = slow queries, because Spark has to open each one.\n",
    "\n",
    "3Ô∏è‚É£ **It merges them into larger Parquet files**\n",
    "\n",
    "* `OPTIMIZE` groups small files together into bigger ones (100‚Äì1000 MB each).\n",
    "* These larger files are faster to read because Spark can scan fewer files.\n",
    "\n",
    "4Ô∏è‚É£ **It rewrites the Delta log**\n",
    "\n",
    "* The `_delta_log` is updated to point to the new compacted files.\n",
    "* The old files are marked as obsolete (they stay temporarily for time travel).\n",
    "\n",
    "---\n",
    "\n",
    "### üßæ How You‚Äôll Know It Worked\n",
    "\n",
    "After running `OPTIMIZE`, Databricks shows a **result table** like this:\n",
    "\n",
    "| numFilesAdded | numFilesRemoved | totalFilesSizeRemoved | totalFilesSizeAdded | totalBytesRemoved | totalBytesAdded | numOptimizedFiles | durationMs |\n",
    "| ------------- | --------------- | --------------------- | ------------------- | ----------------- | --------------- | ----------------- | ---------- |\n",
    "| 15            | 200             | 1.2 GB                | 400 MB              | 1,200,000,000     | 400,000,000     | 185               | 12,345     |\n",
    "\n",
    "‚úÖ This means:\n",
    "\n",
    "* It **merged 200 small files into 15 bigger files**.\n",
    "* It **freed up space** (or reorganized it).\n",
    "* The operation took a few seconds to minutes depending on data size.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† How to Verify It Worked\n",
    "\n",
    "#### Option 1: Check file count before and after\n",
    "\n",
    "```sql\n",
    "DESCRIBE DETAIL gold.transaction;\n",
    "```\n",
    "\n",
    "Look at the **numFiles** and **sizeInBytes** fields ‚Äî after optimization, `numFiles` should drop sharply.\n",
    "\n",
    "#### Option 2: See history log\n",
    "\n",
    "```sql\n",
    "DESCRIBE HISTORY gold.transaction;\n",
    "```\n",
    "\n",
    "You‚Äôll see an entry like:\n",
    "\n",
    "```\n",
    "operation = OPTIMIZE\n",
    "operationParameters = {predicate: '[]'}\n",
    "userName = your.name@databricks.com\n",
    "```\n",
    "\n",
    "#### Option 3: Measure performance\n",
    "\n",
    "Run the same query **before and after** optimization ‚Äî it should execute faster, especially for aggregations.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è When to Run in a Project\n",
    "\n",
    "| Stage                           | When to Run `OPTIMIZE`   | Why                              |\n",
    "| ------------------------------- | ------------------------ | -------------------------------- |\n",
    "| üèóÔ∏è After initial load          | After large batch insert | Consolidate first write          |\n",
    "| üîÅ During pipeline runs         | Daily or weekly          | Clean up after incremental loads |\n",
    "| üìä Before performance testing   | Before heavy queries     | Improve read speed               |\n",
    "| üßº After merging data (upserts) | After `MERGE INTO`       | Remove small delta fragments     |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18423fe2-7814-4707-ae3c-5eb71b359b1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "ZORDER BY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d010c2b-ff82-4c2e-ae74-cc3183db9356",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "What it does:\n",
    "Z-Ordering is like sorting and clustering data in Delta files based on certain columns (e.g., date or customer).\n",
    "This helps Databricks quickly find relevant data during queries instead of scanning the whole dataset.\n",
    "-------------------------------------------------------------------------------------------------------\n",
    " Example:\n",
    "OPTIMIZE gold.transaction\n",
    "ZORDER BY (TransactionDate, CustomerID);\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Why it‚Äôs important:\n",
    "‚Ä¢\tSpeeds up queries that filter or join on specific columns\n",
    "‚Ä¢\tReduces scan time and cost\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "‚è∞ When to use:\n",
    "‚Ä¢\tAfter running OPTIMIZE\n",
    "‚Ä¢\tOn columns frequently used in WHERE, GROUP BY, or JOIN\n",
    "________________________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a08d6b25-f790-4262-b8c7-3cf36aa2b3da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "spark.sql(\"OPTIMIZE gold.transaction ZORDER BY (TransactionDate, CustomerID)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea32bbbf-721c-4124-991c-fbb9423eb53a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3782bbe6-517d-4f6a-96ff-f7731be5e8d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "DESCRIBE HISTORY\n",
    "üîπ What it does:\n",
    "This shows the audit log (or ‚Äútimeline‚Äù) of every change made to a Delta table ‚Äî inserts, updates, deletes, optimizations, etc.\n",
    "----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "üìà Why it‚Äôs important:\n",
    "‚Ä¢\tHelps you track when data changed\n",
    "‚Ä¢\tUseful for debugging ETL jobs\n",
    "‚Ä¢\tHelps identify which version to restore or time travel to\n",
    "----------------------------------------------------------------------------------------------------------------\n",
    "‚è∞ When to use:\n",
    "‚Ä¢\tBefore and after updates/deletes\n",
    "‚Ä¢\tBefore VACUUM to check versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcc9c5bb-dd59-4c07-ad37-be26d4cff665",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_history = spark.sql(\"DESCRIBE HISTORY gold.transaction\")\n",
    "display(df_history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d3a6451-3891-4fcf-9601-c0a3703f300d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "TIME TRAVEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64dd9f2e-4ab4-4fda-8c51-7e4e2f8c6f97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "üîπ What it does:\n",
    "Delta Lake automatically keeps older versions of your data.\n",
    "You can query or restore them using version number or timestamp.\n",
    "-----------------------------------------------------------------------------------------\n",
    "\n",
    "üìà Why it‚Äôs important:\n",
    "‚Ä¢\tLets you undo accidental changes\n",
    "‚Ä¢\tAllows data audits and reproducible analysis\n",
    "‚Ä¢\tEnables debugging (\"What did the table look like last week?\")\n",
    "-----------------------------------------------------------------------------------------\n",
    "‚è∞ When to use:\n",
    "‚Ä¢\tBefore or after major updates\n",
    "‚Ä¢\tDuring audits or validation checks\n",
    "________________________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1597d031-72f9-4de4-b721-0cb2343d1156",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM gold.transaction VERSION AS OF 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9a39e6a-ab5e-42cb-9775-8fe8f5f041c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Or by timestamp\n",
    "SELECT * FROM gold.transaction TIMESTAMP AS OF '2025-11-19 14:00:07';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff140827-7bb0-44e4-99dd-eb1618ed5575",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "RESTORE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "648b5d45-d37d-4f7c-9be5-9cff6d67f44f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "üîπ What it does:\n",
    "This restores your Delta table to a specific previous version.\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "üìà Why it‚Äôs important:\n",
    "‚Ä¢\tQuickly roll back to a good version if something goes wrong\n",
    "‚Ä¢\tSaves hours compared to reloading from scratch\n",
    "-------------------------------------------------------------------------\n",
    "‚è∞ When to use:\n",
    "‚Ä¢\tAfter a bad data load, delete, or corruption\n",
    "________________________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31ab5f65-e756-4336-aad5-5ec34556993c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "RESTORE TABLE gold.transaction TO VERSION AS OF 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ad653a8-21dd-41fa-a5cf-12f42462da01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "VACCUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7428c93-0310-485b-96a1-66e1df27a010",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "üîπ What it does:\n",
    "Deletes old Parquet files that are no longer referenced by the Delta transaction log.\n",
    "By default, Delta keeps old data files for 7 days for time travel.\n",
    "------------------------------------------------------------------------------------\n",
    "üìà Why it‚Äôs important:\n",
    "‚Ä¢\tFrees up storage space\n",
    "‚Ä¢\tRemoves stale file references\n",
    "‚Ä¢\tImproves performance on large tables\n",
    "-----------------------------------------------------------------------------------\n",
    "‚ö†Ô∏è Caution:\n",
    "Once you VACUUM, you can‚Äôt time travel to versions older than the retention period.\n",
    "-----------------------------------------------------------------------------------\n",
    "‚è∞ When to use:\n",
    "‚Ä¢\tAfter confirming your data is stable\n",
    "‚Ä¢\tIn scheduled maintenance jobs (e.g., weekly or monthly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "864d3313-1a07-4bf3-931b-43c775a5e49f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "-- Normal cleanup\n",
    "VACUUM gold.transaction;\n",
    "\n",
    "-- Aggressive cleanup (for testing)\n",
    "VACUUM gold.transaction RETAIN 0 HOURS;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5597925843457317,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Delta Lake maintenance command",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
