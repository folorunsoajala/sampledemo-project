{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae81c313-ef67-4fc0-9153-6d5da3ba61ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First create another container (Gold layer) on your adls and create external location on databricks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ebab683-0178-452f-a6c8-26de8f6dc079",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You need to add a storage path to your catalog creation command — something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ba36bb7-cc29-4d77-9a02-e78bedeb629f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create Catalog and Schema\n",
    "spark.sql(\"\"\"\n",
    "CREATE CATALOG IF NOT EXISTS safe_sure_catalog\n",
    "MANAGED LOCATION 'abfss://gold-layer@sampledemos.dfs.core.windows.net/'\n",
    "\"\"\")\n",
    "\n",
    "# Switch to the Catalog\n",
    "spark.sql(\"USE CATALOG safe_sure_catalog\")\n",
    "\n",
    "# Create Schema (use either DATABASE or SCHEMA — they are synonyms in Databricks)\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS gold\")\n",
    "spark.sql(\"USE gold\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a229ba5-63a8-4032-8e14-2e8adc84f4ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create the Incident Delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a025b8a4-1fff-45af-a847-88a47cfd51d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS gold.incident (\n",
    "    IncidentID STRING,\n",
    "    ClaimID STRING,\n",
    "    IncidentDate DATE,\n",
    "    IncidentType STRING,\n",
    "    Severity STRING,\n",
    "    Description STRING\n",
    ")\n",
    "USING DELTA;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10eb48d5-7109-463d-b467-550065c91a0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load the data from the silver layer \n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").csv(\"abfss://landingzone@sampledemos.dfs.core.windows.net/Incident.csv\")\n",
    "\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "# Data Cleaning\n",
    "df_clean = (df\n",
    "    .withColumn(\"IncidentDate\", F.to_date(\"IncidentDate\", \"yyyy/MM/dd\"))\n",
    "    .withColumn(\"IncidentType\", F.trim(F.initcap(\"IncidentType\")))\n",
    "    .withColumn(\"Severity\", F.upper(F.trim(\"Severity\")))\n",
    ")\n",
    "\n",
    "# Save cleaned data to Delta table\n",
    "df_clean.write.mode(\"overwrite\").saveAsTable(\"gold.incident\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a68e8a23-44c4-4da0-8e92-1a62339b4311",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from gold.incident"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5720909349993830,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Incident_Gold_table",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
